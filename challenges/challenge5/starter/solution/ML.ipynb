{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import Data"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\r\n",
        "import io\r\n",
        "import requests\r\n",
        "from azureml.core import Dataset, Datastore\r\n",
        "from azureml.data.datapath import DataPath\r\n",
        "\r\n",
        "url=\"https://raw.githubusercontent.com/ColdStart-Challenge/ColdStart-Challenge-2021/main/challenges/challenge5/starter/data/coldstart-historical-sales.csv\"\r\n",
        "s=requests.get(url).content\r\n",
        "df=pd.read_csv(io.StringIO(s.decode('utf-8')))\r\n",
        "\r\n",
        "df_tab = Dataset.Tabular.from_delimited_files(url)\r\n",
        "\r\n",
        "X_tab = df_tab.drop_columns(\"count\")\r\n",
        "y_tab = df_tab.keep_columns(\"count\")\r\n",
        "\r\n",
        "df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 39,
          "data": {
            "text/plain": "         datetime  season  holiday  workingday  weather  temp   atemp  \\\n0  5/22/2019 0:00       1        0           0        1  9.84  14.395   \n1  5/22/2019 1:00       1        0           0        1  9.02  13.635   \n2  5/22/2019 2:00       1        0           0        1  9.02  13.635   \n3  5/22/2019 3:00       1        0           0        1  9.84  14.395   \n4  5/22/2019 4:00       1        0           0        1  9.84  14.395   \n\n   humidity  windspeed  count  \n0        81        0.0     16  \n1        80        0.0     40  \n2        80        0.0     32  \n3        75        0.0     13  \n4        75        0.0      1  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>datetime</th>\n      <th>season</th>\n      <th>holiday</th>\n      <th>workingday</th>\n      <th>weather</th>\n      <th>temp</th>\n      <th>atemp</th>\n      <th>humidity</th>\n      <th>windspeed</th>\n      <th>count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5/22/2019 0:00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>9.84</td>\n      <td>14.395</td>\n      <td>81</td>\n      <td>0.0</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5/22/2019 1:00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>9.02</td>\n      <td>13.635</td>\n      <td>80</td>\n      <td>0.0</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5/22/2019 2:00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>9.02</td>\n      <td>13.635</td>\n      <td>80</td>\n      <td>0.0</td>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5/22/2019 3:00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>9.84</td>\n      <td>14.395</td>\n      <td>75</td>\n      <td>0.0</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5/22/2019 4:00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>9.84</td>\n      <td>14.395</td>\n      <td>75</td>\n      <td>0.0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 39,
      "metadata": {
        "gather": {
          "logged": 1621617571013
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transform Data"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\r\n",
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "\r\n",
        "df = df[[\"season\", \"holiday\", \"workingday\", \"weather\", \"temp\", \"atemp\", \"humidity\", \"windspeed\", \"count\"]]\r\n",
        "\r\n",
        "#Count Missing Values\r\n",
        "print(\" \\nCount missing values: \",\r\n",
        "       df.isnull().sum().sum())\r\n",
        "\r\n",
        "#No Missing Values, so no cleaning needed\r\n",
        "\r\n",
        "#Set categorical variables as categorical\r\n",
        "\r\n",
        "df[\"season\"] = df[\"season\"].astype(\"category\")\r\n",
        "df[\"weather\"] = df[\"weather\"].astype(\"category\")\r\n",
        "\r\n",
        "#Shuffle the data:\r\n",
        "df = df.sample(frac=1)\r\n",
        "\r\n",
        "#Set feature and target variables\r\n",
        "X = df.iloc[:, [0,1,2,3,4,5,6,7]]\r\n",
        "y = df.iloc[:, 8]\r\n",
        "\r\n",
        "#Normalize data\r\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\r\n",
        "X = scaler.fit_transform(X)\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "Count missing values:  0\n"
          ]
        }
      ],
      "execution_count": 42,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1621617608091
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K-Fold CV and Training"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_regression\r\n",
        "from sklearn.ensemble import RandomForestRegressor\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "param_grid = {'max_depth': [2, 5, 10],\r\n",
        "              'min_samples_split': [2, 5, 10]}\r\n",
        "\r\n",
        "base_estimator = RandomForestRegressor(random_state=0)\r\n",
        "\r\n",
        "sh = GridSearchCV(base_estimator, param_grid, cv=10, scoring='r2').fit(X, y)\r\n",
        "best_model = sh.best_estimator_\r\n",
        "best_score = sh.best_score_\r\n",
        "print('Best Model: ', best_model, '\\n with score: ', best_score)\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Model:  RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
            "                      max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
            "                      max_samples=None, min_impurity_decrease=0.0,\n",
            "                      min_impurity_split=None, min_samples_leaf=1,\n",
            "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
            "                      random_state=0, verbose=0, warm_start=False) \n",
            " with score:  0.3664615637254064\n"
          ]
        }
      ],
      "execution_count": 44,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1621617787432
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\r\n",
        "joblib.dump(sh, 'sklearn_regression_model.pkl')"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 45,
          "data": {
            "text/plain": "['sklearn_regression_model.pkl']"
          },
          "metadata": {}
        }
      ],
      "execution_count": 45,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1621617793093
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Registering the Model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\r\n",
        "\r\n",
        "from azureml.core import Workspace\r\n",
        "from azureml.core import Model\r\n",
        "from azureml.core.resource_configuration import ResourceConfiguration\r\n",
        "\r\n",
        "ws = Workspace.from_config()\r\n",
        "\r\n",
        "model = Model.register(workspace=ws,\r\n",
        "                       model_name='my-sklearn-model',                # Name of the registered model in your workspace.\r\n",
        "                       model_path='./sklearn_regression_model.pkl',  # Local file to upload and register as a model.\r\n",
        "                       model_framework=Model.Framework.SCIKITLEARN,  # Framework used to create the model.\r\n",
        "                       model_framework_version=sklearn.__version__,  # Version of scikit-learn used to create the model.\r\n",
        "                       sample_input_dataset=X_tab,\r\n",
        "                       sample_output_dataset=y_tab,\r\n",
        "                       resource_configuration=ResourceConfiguration(cpu=2, memory_in_gb=4),\r\n",
        "                       description='Regression model to predict Ice Cream Sales.')\r\n",
        "\r\n",
        "print('Name:', model.name)\r\n",
        "print('Version:', model.version)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Registering model my-sklearn-model\n",
            "Name: my-sklearn-model\n",
            "Version: 2\n"
          ]
        }
      ],
      "execution_count": 46,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1621617799198
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Scoring Script"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile score.py\r\n",
        "\r\n",
        "import json\r\n",
        "import pickle\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import os\r\n",
        "import joblib\r\n",
        "from azureml.core.model import Model\r\n",
        "\r\n",
        "from inference_schema.schema_decorators import input_schema, output_schema\r\n",
        "from inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\r\n",
        "from inference_schema.parameter_types.pandas_parameter_type import PandasParameterType\r\n",
        "\r\n",
        "\r\n",
        "def init():\r\n",
        "    global model\r\n",
        "    # Replace filename if needed.\r\n",
        "    path = os.getenv('AZUREML_MODEL_DIR') \r\n",
        "    model_path = os.path.join(path, 'sklearn_regression_model.pkl')\r\n",
        "    # Deserialize the model file back into a sklearn model.\r\n",
        "    model = joblib.load(model_path)\r\n",
        "\r\n",
        "\r\n",
        "input_sample = pd.DataFrame(data=[{\r\n",
        "    \"season\": 1,\r\n",
        "    \"holiday\": 0,\r\n",
        "    \"workingday\": 0,\r\n",
        "    \"weater\": 1,\r\n",
        "    \"temp\": 9.84,\r\n",
        "    \"atemp\": 10.254,\r\n",
        "    \"humidity\": 81,\r\n",
        "    \"windspeed\": 0.0\r\n",
        "}])\r\n",
        "\r\n",
        "# This is an integer type sample. Use the data type that reflects the expected result.\r\n",
        "output_sample = np.array([0])\r\n",
        "\r\n",
        "# To indicate that we support a variable length of data input,\r\n",
        "# set enforce_shape=False\r\n",
        "@input_schema('data', PandasParameterType(input_sample))\r\n",
        "@output_schema(NumpyParameterType(output_sample))\r\n",
        "def run(data):\r\n",
        "    try:\r\n",
        "        print(\"input_data....\")\r\n",
        "        print(data.columns)\r\n",
        "        print(type(data))\r\n",
        "        result = model.predict(data)\r\n",
        "        print(\"result.....\")\r\n",
        "        print(result)\r\n",
        "    # You can return any data type, as long as it can be serialized by JSON.\r\n",
        "        return result.tolist()\r\n",
        "    except Exception as e:\r\n",
        "        error = str(e)\r\n",
        "        return error"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting score.py\n"
          ]
        }
      ],
      "execution_count": 47,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define custom Environment"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.model import InferenceConfig\r\n",
        "from azureml.core import Environment\r\n",
        "from azureml.core.conda_dependencies import CondaDependencies\r\n",
        "\r\n",
        "environment = Environment('my-sklearn-environment')\r\n",
        "environment.python.conda_dependencies = CondaDependencies.create(pip_packages=[\r\n",
        "    'azureml-defaults',\r\n",
        "    'inference-schema[numpy-support]',\r\n",
        "    'joblib',\r\n",
        "    'numpy',\r\n",
        "    'pandas',\r\n",
        "    'scikit-learn=={}'.format(sklearn.__version__)\r\n",
        "])\r\n",
        "\r\n",
        "inference_config = InferenceConfig(entry_script='./score.py',environment=environment)"
      ],
      "outputs": [],
      "execution_count": 48,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1621617807375
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deploy Model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "service_name = 'my-coldstart-model'\r\n",
        "\r\n",
        "service = Model.deploy(ws, service_name, [model], inference_config, overwrite=True)\r\n",
        "service.wait_for_deployment(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
            "Running\n",
            "2021-05-21 17:23:32+00:00 Creating Container Registry if not exists.\n",
            "2021-05-21 17:23:32+00:00 Registering the environment.\n",
            "2021-05-21 17:23:33+00:00 Use the existing image.\n",
            "2021-05-21 17:23:33+00:00 Generating deployment configuration.\n",
            "2021-05-21 17:23:34+00:00 Submitting deployment to compute.\n",
            "2021-05-21 17:23:37+00:00 Checking the status of deployment my-coldstart-model..\n",
            "2021-05-21 17:23:48+00:00 Checking the status of inference endpoint my-coldstart-model.\n",
            "Succeeded\n",
            "ACI service creation operation finished, operation \"Succeeded\"\n"
          ]
        }
      ],
      "execution_count": 49,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1621617859407
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# JSON"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\r\n",
        "\r\n",
        "input_payload = json.dumps({\r\n",
        "    'data':df.iloc[[0, 1, 2],[0,1,2,3,4,5,6,7]].values.tolist()\r\n",
        "})\r\n",
        "\r\n",
        "output = service.run(input_payload)\r\n",
        "\r\n",
        "print(output)\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[407.0327391774891, 346.33451515151506, 336.798755952381]\n"
          ]
        }
      ],
      "execution_count": 50,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1621617861200
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Redeploy to ACI"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.webservice import AciWebservice\r\n",
        "\r\n",
        "deployment_config = AciWebservice.deploy_configuration(\r\n",
        "    cpu_cores=0.5, memory_gb=1, auth_enabled=True\r\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 51,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1621618141521
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "service = Model.deploy(\r\n",
        "    ws,\r\n",
        "    \"myservice\",\r\n",
        "    [model],\r\n",
        "    inference_config,\r\n",
        "    deployment_config,\r\n",
        "    overwrite=True,\r\n",
        ")\r\n",
        "service.wait_for_deployment(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
            "Running\n",
            "2021-05-21 17:29:07+00:00 Creating Container Registry if not exists.\n",
            "2021-05-21 17:29:07+00:00 Registering the environment.\n",
            "2021-05-21 17:29:08+00:00 Use the existing image.\n",
            "2021-05-21 17:29:08+00:00 Generating deployment configuration.\n",
            "2021-05-21 17:29:09+00:00 Submitting deployment to compute..\n",
            "2021-05-21 17:29:32+00:00 Checking the status of deployment myservice..\n",
            "2021-05-21 17:31:24+00:00 Checking the status of inference endpoint myservice.\n",
            "Succeeded\n",
            "ACI service creation operation finished, operation \"Succeeded\"\n"
          ]
        }
      ],
      "execution_count": 52,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1621618289638
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(service.get_logs())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-05-21T17:31:13,627134839+00:00 - rsyslog/run \n",
            "2021-05-21T17:31:13,629610549+00:00 - iot-server/run \n",
            "2021-05-21T17:31:13,634830170+00:00 - gunicorn/run \n",
            "2021-05-21T17:31:13,629025847+00:00 - nginx/run \n",
            "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
            "2021-05-21T17:31:13,863191275+00:00 - iot-server/finish 1 0\n",
            "2021-05-21T17:31:13,864127579+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
            "Starting gunicorn 20.1.0\n",
            "Listening at: http://127.0.0.1:31311 (18)\n",
            "Using worker: sync\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 41\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2021-05-21 17:31:16,583 | root | INFO | Starting up app insights client\n",
            "2021-05-21 17:31:16,584 | root | INFO | Starting up request id generator\n",
            "2021-05-21 17:31:16,584 | root | INFO | Starting up app insight hooks\n",
            "2021-05-21 17:31:16,584 | root | INFO | Invoking user's init function\n",
            "2021-05-21 17:31:17,282 | root | INFO | Users's init has completed successfully\n",
            "2021-05-21 17:31:17,284 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
            "2021-05-21 17:31:17,284 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
            "2021-05-21 17:31:17,285 | root | INFO | Scoring timeout is found from os.environ: 60000 ms\n",
            "2021-05-21 17:31:24,573 | root | INFO | 200\n",
            "127.0.0.1 - - [21/May/2021:17:31:24 +0000] \"GET /swagger.json HTTP/1.0\" 200 2584 \"-\" \"Go-http-client/1.1\"\n",
            "2021-05-21 17:31:29,178 | root | INFO | 200\n",
            "127.0.0.1 - - [21/May/2021:17:31:29 +0000] \"GET /swagger.json HTTP/1.0\" 200 2584 \"-\" \"Go-http-client/1.1\"\n",
            "\n"
          ]
        }
      ],
      "execution_count": 53,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1621618344592
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\r\n",
        "import json\r\n",
        "from azureml.core import Webservice\r\n",
        "\r\n",
        "service = Webservice(workspace=ws, name=\"myservice\")\r\n",
        "scoring_uri = service.scoring_uri\r\n",
        "\r\n",
        "# If the service is authenticated, set the key or token\r\n",
        "key, _ = service.get_keys()\r\n",
        "\r\n",
        "# Set the appropriate headers\r\n",
        "headers = {\"Content-Type\": \"application/json\"}\r\n",
        "headers[\"Authorization\"] = f\"Bearer {key}\"\r\n",
        "\r\n",
        "# Make the request and display the response and logs\r\n",
        "data = json.dumps({\r\n",
        "    'data':df.iloc[[0, 1, 2],[0,1,2,3,4,5,6,7]].values.tolist()\r\n",
        "})\r\n",
        "resp = requests.post(scoring_uri, data=data, headers=headers)\r\n",
        "print(resp.text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[407.0327391774891, 346.33451515151506, 336.798755952381]\n"
          ]
        }
      ],
      "execution_count": 54,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1621618354301
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}